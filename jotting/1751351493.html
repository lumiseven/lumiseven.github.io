<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>LLM模型的训练阶段有哪些基础的步骤 | Lumiseven's blog</title>
    <meta name="description" content="lumiseven's personal blog.">
    <link rel="preload stylesheet" href="/assets/style.2df32089.css" as="style">
    <link rel="modulepreload" href="/assets/app.bd26c8cd.js">
    <link rel="modulepreload" href="/assets/jotting_1751351493.md.4ee4920f.lean.js">
    
    <meta name="theme-color" content="#3c8772">
  <script id="check-dark-light">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-93a960b4><!--[--><!--]--><!--[--><span tabindex="-1" data-v-151f2593></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-151f2593> Skip to content </a><!--]--><!----><header class="VPNav" data-v-93a960b4 data-v-0fa0e57d><div class="VPNavBar has-sidebar" data-v-0fa0e57d data-v-be450ad9><div class="container" data-v-be450ad9><div class="title" data-v-be450ad9><div class="VPNavBarTitle has-sidebar" data-v-be450ad9 data-v-6d2fb2d9><a class="title" href="/" data-v-6d2fb2d9><!--[--><!--]--><!----><!--[-->Lumiseven&#39;s blog<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-be450ad9><div class="curtain" data-v-be450ad9></div><div class="content-body" data-v-be450ad9><!--[--><!--]--><!----><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-be450ad9 data-v-bdedfc22><span id="main-nav-aria-label" class="visually-hidden" data-v-bdedfc22>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/doc/index" data-v-bdedfc22 data-v-f2ec7ecf data-v-a8b5c975><!--[-->Document<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/jotting/index" data-v-bdedfc22 data-v-f2ec7ecf data-v-a8b5c975><!--[-->Jotting<!--]--><!----></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-be450ad9 data-v-da3f667a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-da3f667a data-v-0d529b6d data-v-f3c41672><span class="check" data-v-f3c41672><span class="icon" data-v-f3c41672><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-0d529b6d><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-0d529b6d><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-be450ad9 data-v-2ab2a029 data-v-f6988cfb><!--[--><a class="VPSocialLink" href="https://github.com/lumiseven/" target="_blank" rel="noopener" data-v-f6988cfb data-v-e57698f6><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-be450ad9 data-v-66bb1f24 data-v-96001b6b><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-96001b6b><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-96001b6b><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-96001b6b><div class="VPMenu" data-v-96001b6b data-v-e7ea1737><!----><!--[--><!--[--><!----><div class="group" data-v-66bb1f24><div class="item appearance" data-v-66bb1f24><p class="label" data-v-66bb1f24>Appearance</p><div class="appearance-action" data-v-66bb1f24><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-66bb1f24 data-v-0d529b6d data-v-f3c41672><span class="check" data-v-f3c41672><span class="icon" data-v-f3c41672><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-0d529b6d><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-0d529b6d><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-66bb1f24><div class="item social-links" data-v-66bb1f24><div class="VPSocialLinks social-links-list" data-v-66bb1f24 data-v-f6988cfb><!--[--><a class="VPSocialLink" href="https://github.com/lumiseven/" target="_blank" rel="noopener" data-v-f6988cfb data-v-e57698f6><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-be450ad9 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav" data-v-93a960b4 data-v-2817d72e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-2817d72e><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-2817d72e><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-2817d72e>Menu</span></button><a class="top-link" href="#" data-v-2817d72e>Return to top</a></div><aside class="VPSidebar" data-v-93a960b4 data-v-c79ccefa><div class="curtain" data-v-c79ccefa></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-c79ccefa><span class="visually-hidden" id="sidebar-aria-label" data-v-c79ccefa> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>Daily test</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/jotting/1678330412" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>1678330412</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/jotting/1678891164" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>1678891164</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/jotting/1678937136" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>1678937136</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/jotting/es_tmp_1" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>记一次ES查询优化</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/jotting/python_generate_qrcode" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>python 生成 qrcode</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/jotting/python_calculate_derivative" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>python 计算导数和积分</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/jotting/python_remove_image_background" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>python 使用 u2net 移除图片背景</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/jotting/python_port_scanner" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>python 扫描服务器端口</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-93a960b4 data-v-0bd490fb><div class="VPDoc has-sidebar has-aside" data-v-0bd490fb data-v-c5936a1e><div class="container" data-v-c5936a1e><div class="aside" data-v-c5936a1e><div class="aside-curtain" data-v-c5936a1e></div><div class="aside-container" data-v-c5936a1e><div class="aside-content" data-v-c5936a1e><div class="VPDocAside" data-v-c5936a1e data-v-cdc66372><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" data-v-cdc66372 data-v-5dd9d5f6><div class="content" data-v-5dd9d5f6><div class="outline-marker" data-v-5dd9d5f6></div><div class="outline-title" data-v-5dd9d5f6>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-5dd9d5f6><span class="visually-hidden" id="doc-outline-aria-label" data-v-5dd9d5f6> Table of Contents for current page </span><ul class="root" data-v-5dd9d5f6 data-v-1188541a><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-cdc66372></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-c5936a1e><div class="content-container" data-v-c5936a1e><!--[--><!--]--><main class="main" data-v-c5936a1e><div style="position:relative;" class="vp-doc _jotting_1751351493" data-v-c5936a1e><div><h1 id="llm模型的训练阶段有哪些基础的步骤" tabindex="-1">LLM模型的训练阶段有哪些基础的步骤 <a class="header-anchor" href="#llm模型的训练阶段有哪些基础的步骤" aria-hidden="true">#</a></h1><p>LLM模型（大型语言模型）的训练阶段是一个复杂且迭代的过程，涉及多个基础步骤。以下是这些步骤的详细分解：</p><p><strong>1. 数据收集与预处理 (Data Collection and Preprocessing)</strong></p><p>这是训练的基石，重要性怎么强调都不为过。</p><ul><li><strong>数据来源：</strong><ul><li><strong>文本数据：</strong> 网页抓取数据（Common Crawl）、图书语料库（BookCorpus）、维基百科、Reddit、新闻文章、代码库（GitHub）、论坛、学术论文等。</li><li><strong>代码数据：</strong> GitHub、各种开源项目的代码。</li><li><strong>多模态数据（对于多模态LLM）：</strong> 图像-文本对、视频-文本对等。</li></ul></li><li><strong>清洗与过滤：</strong><ul><li><strong>去重：</strong> 删除完全相同的或高度相似的文档，避免模型过拟合到特定文本或数据泄露。</li><li><strong>低质量内容过滤：</strong> 删除包含大量乱码、HTML标记、重复短语、非自然语言表达、模板化内容等。</li><li><strong>语言识别与过滤：</strong> 确保只保留目标语言（如果只训练单一语言模型）。</li><li><strong>隐私信息移除：</strong> 识别并去除个人身份信息（PII），如姓名、地址、电话、邮箱、身份证号等。</li><li><strong>安全性过滤：</strong> 移除或标记有害、偏见、仇恨言论等内容，或至少在训练后进行对齐处理。</li><li><strong>长度过滤：</strong> 移除过短或过长的文档，可能不包含有意义的信息。</li></ul></li><li><strong>格式统一：</strong> 将所有文本转换为统一的编码（如UTF-8）和格式。</li><li><strong>标准化：</strong> 文本小写化、去除标点符号（取决于具体任务）、数字处理等。</li><li><strong>分词 (Tokenization)：</strong><ul><li>将原始文本分解成模型可以理解的最小单位（Tokens）。</li><li>常用的分词器有：WordPiece, BPE (Byte Pair Encoding), SentencePiece。这些分词器能有效地处理未知词汇（OOV）问题，并通过子词（subword）单元来平衡词汇表大小和表示能力。每个token都会被映射到一个唯一的整数ID。</li></ul></li></ul><p><strong>2. 模型架构选择与初始化 (Model Architecture Selection and Initialization)</strong></p><ul><li><strong>选择预训练模型架构：</strong><ul><li>当前主流的LLM通常基于 <strong>Transformer</strong> 架构。</li><li><strong>编码器-解码器 (Encoder-Decoder)：</strong> 如T5, BART（适用于机器翻译、摘要等）。</li><li><strong>仅解码器 (Decoder-only)：</strong> 如GPT系列，Llama系列（适用于文本生成、对话、问答等），是目前LLM的主流范式。</li><li><strong>仅编码器 (Encoder-only)：</strong> 如BERT（适用于理解任务，如分类、序列标注等，较少用于纯粹的“生成式”LLM）。</li></ul></li><li><strong>模型规模确定：</strong> 根据可用计算资源和训练数据量，决定模型的层数（Layers）、注意力头数（Attention Heads）、隐层维度（Hidden Size）等参数，从而确定总参数量（例如，数十亿到数千亿）。</li><li><strong>参数初始化：</strong><ul><li>模型的权重（parameters）在训练开始时需要被初始化。</li><li>通常使用随机初始化（如高斯分布、截断正态分布）或特定初始化策略（如Xavier初始化、He初始化）来打破对称性，并帮助梯度流动。</li></ul></li></ul><p><strong>3. 预训练 (Pre-training)</strong></p><p>这是LLM训练的核心阶段，通常是 <strong>无监督</strong> 或 <strong>自监督</strong> 的。</p><ul><li><strong>目标：</strong> 让模型从海量无标签文本中学习语言的统计规律、语法、语义、事实知识以及世界观。</li><li><strong>任务类型：</strong><ul><li><strong>自回归语言建模 (Autoregressive Language Modeling - Causal Language Modeling)：</strong><ul><li>最常用和最有效的方法。</li><li>模型被训练来预测序列中的下一个词（或token），只允许关注当前词之前的词，不允许偷看未来的词。</li><li>例如：给定“我爱北京天安”，模型预测下一个词很可能是“门”。</li><li>这是GPT系列、Llama系列等模型采用的训练方式，非常适合生成任务。</li></ul></li><li><strong>掩码语言建模 (Masked Language Modeling - MLM)：</strong><ul><li>BERT系列模型的主要训练任务。</li><li>模型被训练来预测文本中被随机遮蔽（mask）的词（或token），可以同时关注被遮蔽词的前后语境。</li><li>例如：给定“我爱[MASK]天[MASK]”，模型预测[MASK]是“北京”和“安门”。</li><li>更侧重于上下文理解能力。</li></ul></li><li><strong>填充空白 (Infilling)：</strong> 类似MLM，但可能遮蔽连续的片段，并让模型填充。</li><li><strong>噪声消除 (Denoising)：</strong> 如T5，给定一个被某种噪声破坏的文本，模型学习恢复原始文本。</li></ul></li><li><strong>损失函数：</strong> 通常是 <strong>交叉熵损失 (Cross-Entropy Loss)</strong>，用于衡量模型预测的下一个token的概率分布与真实下一个token的One-hot编码之间的差异。</li><li><strong>优化器：</strong> 常用的有 <strong>AdamW</strong> (Adam with Weight Decay)，它结合了Adam的优点并加入了权重衰减来防止过拟合。</li><li><strong>学习率调度器 (Learning Rate Scheduler)：</strong> 在训练过程中动态调整学习率。常见的策略有： <ul><li><strong>Warmup：</strong> 初始阶段学习率逐渐增加，以稳定训练。</li><li><strong>Cosine Decay：</strong> 学习率在大部分训练过程中按照余弦函数曲线逐渐下降，直至最小值。</li></ul></li><li><strong>硬件要求：</strong> 需要大量的计算资源，通常是数十甚至数百张高端GPU（如NVIDIA A100）集群，运行数周甚至数月。</li></ul><p><strong>4. 微调 (Fine-tuning) - 可选但常见</strong></p><p>预训练模型已经学习到通用语言知识，但可能在特定任务上表现不佳。微调使其适应特定下游任务。</p><ul><li><strong>目的：</strong> 使模型在特定任务上表现更好，或者使其与人类偏好对齐。</li><li><strong>数据：</strong> 通常是小规模的、高质量的、任务特定的有标签数据。</li><li><strong>任务类型：</strong><ul><li><strong>指令微调 (Instruction Tuning)：</strong><ul><li>通过高质量的指令-响应对来训练模型遵循人类指令，泛化到未见过的指令。</li><li>例如：<code>{&quot;instruction&quot;: &quot;请总结这篇文章。&quot;, &quot;response&quot;: &quot;这篇文章主要讲了...&quot;}</code></li></ul></li><li><strong>监督式微调 (Supervised Fine-tuning - SFT)：</strong><ul><li>直接在特定任务数据集上进行有监督训练，如分类、问答、摘要、翻译等。</li></ul></li><li><strong>多任务微调 (Multi-task Fine-tuning)：</strong><ul><li>在多个相关任务上同时进行微调，提高模型的泛化能力。</li></ul></li></ul></li><li><strong>参数更新：</strong><ul><li>可以更新所有模型参数（全量微调）。</li><li>也可以使用 <strong>参数高效微调 (Parameter Efficient Fine-tuning - PEFT)</strong> 技术，如： <ul><li><strong>LoRA (Low-Rank Adaptation)：</strong> 只训练少量附加的低秩矩阵，大幅减少可训练参数。</li><li><strong>Prefix Tuning / Prompt Tuning：</strong> 通过在输入中添加可学习的“软提示”来引导模型。</li><li><strong>Adapter Tuning：</strong> 在Transformer层之间插入小的可训练模块。</li></ul></li><li>这些方法能显著降低计算和存储需求，并减少灾难性遗忘。</li></ul></li></ul><p><strong>5. 对齐 (Alignment) - 专门针对类ChatGPT模型</strong></p><p>这是让LLM变得“有用”和“安全”的关键步骤，通常在指令微调之后进行。</p><ul><li><strong>目的：</strong><ul><li><strong>有用性 (Helpfulness)：</strong> 使模型生成有用、准确、相关、详尽的回答。</li><li><strong>无害性 (Harmlessness)：</strong> 避免生成有害、偏见、不安全、冒犯性的内容。</li><li><strong>诚实性 (Honesty)：</strong> 减少幻觉（hallucination）和生成不真实的信息。</li></ul></li><li><strong>常用方法：</strong><ul><li><strong>基于人类反馈的强化学习 (Reinforcement Learning from Human Feedback - RLHF)：</strong><ol><li><strong>数据收集与SFT：</strong> 收集人类偏好数据（比较不同模型的响应并进行排名）。</li><li><strong>训练奖励模型 (Reward Model - RM)：</strong> 基于人类偏好数据训练一个独立的奖励模型，该模型能评估LLM生成的文本质量，给出分数。</li><li><strong>强化学习微调 (RL Fine-tuning)：</strong> 使用奖励模型作为奖励函数，通过强化学习算法（如PPO - Proximal Policy Optimization）微调LLM，使其生成高奖励的响应。 <ul><li>LLM充当策略（Policy），奖励模型提供环境反馈。</li><li>PPO优化LLM的参数，使其生成的响应在人类偏好上得分更高。</li></ul></li></ol></li></ul></li></ul><p><strong>6. 评估与部署 (Evaluation and Deployment)</strong></p><ul><li><strong>模型评估：</strong><ul><li><strong>客观指标：</strong><ul><li><strong>困惑度 (Perplexity - PPL)：</strong> 衡量模型预测下一个词的好坏，PPL越低越好。</li><li><strong>BLEU, ROUGE：</strong> 用于机器翻译和摘要等生成任务。</li><li><strong>F1-score, Accuracy：</strong> 用于分类等理解任务。</li></ul></li><li><strong>人类评估 (Human Evaluation)：</strong><ul><li>这是LMM质量的黄金标准。人类专家评估模型输出的流畅性、连贯性、事实准确性、相关性、有用性、安全性等。</li></ul></li><li><strong>基准测试 (Benchmarks)：</strong> 在标准数据集上进行评估，如MMLU (Massive Multitask Language Understanding)、HellaSwag、ARC、TruthfulQA等，以衡量模型的通用能力。</li></ul></li><li><strong>部署：</strong><ul><li>将训练好的模型部署到生产环境，供用户使用。这通常涉及： <ul><li>模型量化 (Quantization)：减少模型大小和计算需求。</li><li>模型蒸馏 (Distillation)：训练一个小模型来模仿大模型的行为。</li><li>使用高性能推理框架（如Hugging Face TGI, vLLM, TensorRT-LLM）。</li><li>API接口设计等。</li></ul></li></ul></li></ul><p>这些步骤共同构成了LLM从原始数据到可部署模型的完整生命周期，体现了数据驱动、大规模训练和人类对齐的核心思想。</p></div></div></main><!--[--><!--]--><footer class="VPDocFooter" data-v-c5936a1e data-v-2813752b><div class="edit-info" data-v-2813752b><div class="edit-link" data-v-2813752b><span class="VPLink edit-link-button" data-v-2813752b data-v-a8b5c975><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="edit-link-icon" data-v-2813752b><path d="M18,23H4c-1.7,0-3-1.3-3-3V6c0-1.7,1.3-3,3-3h7c0.6,0,1,0.4,1,1s-0.4,1-1,1H4C3.4,5,3,5.4,3,6v14c0,0.6,0.4,1,1,1h14c0.6,0,1-0.4,1-1v-7c0-0.6,0.4-1,1-1s1,0.4,1,1v7C21,21.7,19.7,23,18,23z"></path><path d="M8,17c-0.3,0-0.5-0.1-0.7-0.3C7,16.5,6.9,16.1,7,15.8l1-4c0-0.2,0.1-0.3,0.3-0.5l9.5-9.5c1.2-1.2,3.2-1.2,4.4,0c1.2,1.2,1.2,3.2,0,4.4l-9.5,9.5c-0.1,0.1-0.3,0.2-0.5,0.3l-4,1C8.2,17,8.1,17,8,17zM9.9,12.5l-0.5,2.1l2.1-0.5l9.3-9.3c0.4-0.4,0.4-1.1,0-1.6c-0.4-0.4-1.2-0.4-1.6,0l0,0L9.9,12.5z M18.5,2.5L18.5,2.5L18.5,2.5z"></path></svg> Edit this page on GitHub<!--]--><!----></span></div><div class="last-updated" data-v-2813752b><p class="VPLastUpdated" data-v-2813752b data-v-355aa5ef>Last updated: <time datetime="2025-07-01T10:58:09.000Z" data-v-355aa5ef></time></p></div></div><div class="prev-next" data-v-2813752b><div class="pager" data-v-2813752b><!----></div><div class="pager" data-v-2813752b><a class="pager-link next" href="/jotting/1678330412" data-v-2813752b><span class="desc" data-v-2813752b>Next page</span><span class="title" data-v-2813752b>1678330412</span></a></div></div></footer><!--[--><!--]--></div></div></div></div></div><footer class="VPFooter has-sidebar" data-v-93a960b4 data-v-d24360a6><div class="container" data-v-d24360a6><p class="message" data-v-d24360a6>Released under the MIT License.</p><p class="copyright" data-v-d24360a6>Copyright © 2015-present Lumiseven</p></div></footer><!--[--><!--]--></div></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"doc_ai_openai_api-mistral_api.md\":\"37b43f3d\",\"doc_ai_pixtral_12b_video.md\":\"d0ee9f5c\",\"about_about_me.md\":\"3df10914\",\"about_index.md\":\"a2ca1f8d\",\"doc_ai_ai_ide.md\":\"588b5775\",\"doc_ai_chatgpt_embdding.md\":\"11d762e3\",\"doc_ai_common_math_formulas.md\":\"0fa180e8\",\"doc_ai_fine-tuning__fine-tuning.md\":\"dca2fd1b\",\"doc_ai_fine-tuning_fine-tuning_vs_rag.md\":\"8ac676b5\",\"doc_python_python_3_12_new.md\":\"7ea3c570\",\"doc_rdb_mysql_5_7_to_8_0_tips.md\":\"9b58a161\",\"doc_rdb_mysqlfulltextsearch.md\":\"6109c2ea\",\"doc_ai_fine-tuning_llama3_fine-tuning.md\":\"daeee71b\",\"doc_rdb_mysqloperation.md\":\"469aedfe\",\"doc_rdb_mysqlquestion.md\":\"7e9ea43f\",\"doc_ai_fine-tuning_llama3_fine-tuning_chinese.md\":\"f880b38c\",\"doc_ai_fine-tuning_llama3_vs_gpt-4.md\":\"d0030272\",\"doc_ai_fine-tuning_phi3_fine-tuning.md\":\"2a8d22ec\",\"doc_ai_langflow.md\":\"e33b7278\",\"doc_ai_llama3-groq-tool.md\":\"7fd9be89\",\"doc_ai_llamaindex_text_to_sql.md\":\"220e59e0\",\"doc_ai_ml_top_10_algorithms_advantages_disadvantages.md\":\"4a460397\",\"doc_ai_ollama.md\":\"ed890140\",\"doc_ai_project.md\":\"eae98df6\",\"doc_ai_prompt-engineering__prompt-engineering.md\":\"54eaa91b\",\"doc_ai_random_forest_model.md\":\"67a2ce24\",\"doc_ai_recommendation_als.md\":\"327249ec\",\"doc_rdb_mysqlvspostgres.md\":\"42fd57cc\",\"doc_rdb_querybigdata.md\":\"0903c318\",\"doc_ai_simulated_annealing.md\":\"fddb25a2\",\"doc_rdb_uuid.md\":\"6d83cf7f\",\"doc_redis_bigkeys.md\":\"5874b1bc\",\"doc_redis_bitmap_user_sign.md\":\"7e7b1616\",\"doc_tools_frp.md\":\"844adf8d\",\"doc_video_collection_agi_arrives_2027.md\":\"784dae1a\",\"doc_video_collection_ai_manipulates_humans.md\":\"79726878\",\"doc_video_collection_ai_safety_governance.md\":\"1bbc9b22\",\"doc_video_collection_ai_understands_time.md\":\"9119328c\",\"doc_video_collection_alexnet_open_source.md\":\"335ce7eb\",\"doc_video_collection_chatgpt_language_model.md\":\"3173fe88\",\"doc_video_collection_does_ai_era_need_programming.md\":\"d95b15f9\",\"doc_es_es_java.md\":\"5888c9cc\",\"doc_video_collection_era_of_experience.md\":\"f5d86371\",\"doc_video_collection_everything_related_to_experience.md\":\"e8114d2c\",\"doc_video_collection_hai_2025.md\":\"3bc5b8af\",\"doc_video_collection_how_large_language_model_works.md\":\"a78131be\",\"doc_video_collection_huggingface_llm_manual.md\":\"df8db12b\",\"doc_video_collection_intelligent_explosion.md\":\"b0e40f7b\",\"doc_video_collection_model_compression_methods.md\":\"6fcb3de0\",\"doc_video_collection_model_is_not_product.md\":\"5e1a7e4d\",\"doc_video_collection_philosophy_to_nobel_prize.md\":\"181d139b\",\"doc_video_collection_why_your_queue_is_slow.md\":\"87ab9199\",\"doc_video_collection_google_agi_plan.md\":\"71748133\",\"doc_video_collection_windsurf.md\":\"1e575d29\",\"index.md\":\"4e06dcea\",\"jotting_1678330412.md\":\"c348be64\",\"jotting_1677990878.md\":\"1435de74\",\"jotting_1678891164.md\":\"92323ddd\",\"jotting_1678937136.md\":\"f206d102\",\"jotting_1680498848.md\":\"f16ad8b8\",\"jotting_1682611195.md\":\"aad360aa\",\"jotting_1751351308.md\":\"26303423\",\"jotting_1751351404.md\":\"0844e156\",\"jotting_1751351493.md\":\"4ee4920f\",\"jotting_es_tmp_1.md\":\"4f6e901e\",\"jotting_index.md\":\"981d0699\",\"jotting_numpy_csv_executable.md\":\"e1e7bd91\",\"jotting_play_win_game_on_linux.md\":\"24f9b2aa\",\"jotting_python_generate_qrcode.md\":\"dea06fba\",\"jotting_python_calculate_derivative.md\":\"90499dce\",\"jotting_python_port_scanner.md\":\"6ba1ec44\",\"jotting_python_remove_image_background.md\":\"0d4d5ca0\",\"jotting_resume.md\":\"26c9cda6\",\"jotting_springboot_make_blog_api.md\":\"4bdcf148\",\"doc_rdb_mysqlspatialindex.md\":\"ff7bfa05\",\"doc_ai_vector_search_library.md\":\"0c4a2602\",\"doc_video_collection_deepmind_alpha_geometry_2.md\":\"d4989b72\",\"doc_python_interpreter.md\":\"518ee890\",\"doc_es_geo.md\":\"37633e0e\",\"doc_es_index.md\":\"dae18b67\",\"doc_es_infrequentoperation.md\":\"5d211a32\",\"doc_git_command.md\":\"146a420d\",\"doc_index.md\":\"185e656a\",\"doc_jvm_bean_copy.md\":\"4859bd0c\",\"doc_jvm_concurrency.md\":\"affea8ac\",\"doc_jvm_concurrency2.md\":\"c79b848d\",\"doc_jvm_coroutines.md\":\"ee9f9275\",\"doc_jvm_guava.md\":\"6ac7d6b0\",\"doc_jvm_hippo4j.md\":\"caaf88bd\",\"doc_jvm_javabase.md\":\"12164ec3\",\"doc_jvm_kotlin_corouties.md\":\"495e015f\",\"doc_jvm_lock4j.md\":\"c664d8bd\",\"doc_jvm_sentinel.md\":\"82e5ed09\",\"doc_jvm_springboot_extension_1.md\":\"eaa7f27c\",\"doc_nginx_caddy.md\":\"a0961eeb\",\"doc_nginx_haproxyandnginx.md\":\"f72b4d24\",\"doc_jvm_core_question.md\":\"d5b33d26\",\"doc_nginx_nginxvscaddy.md\":\"dd8640a0\",\"doc_others_common_heartbeat_detection_algorithms.md\":\"2b8d91ce\",\"doc_others_common_regular_expression.md\":\"3892a44f\",\"doc_nginx_nginx.md\":\"b593a5db\",\"doc_others_http1_1_vs_http2.md\":\"c77d1c56\",\"doc_python_multiprocessing.md\":\"aa83fcfc\"}")</script>
    <script type="module" async src="/assets/app.bd26c8cd.js"></script>
    
  </body>
</html>