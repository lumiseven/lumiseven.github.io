<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Llama3 fine-tuning | Lumiseven's blog</title>
    <meta name="description" content="lumiseven's personal blog.">
    <link rel="preload stylesheet" href="/assets/style.2df32089.css" as="style">
    <link rel="modulepreload" href="/assets/app.413235d3.js">
    <link rel="modulepreload" href="/assets/doc_ai_fine-tuning_llama3_fine-tuning.md.be2d117c.lean.js">
    
    <meta name="theme-color" content="#3c8772">
  <script id="check-dark-light">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-93a960b4><!--[--><!--]--><!--[--><span tabindex="-1" data-v-151f2593></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-151f2593> Skip to content </a><!--]--><!----><header class="VPNav" data-v-93a960b4 data-v-0fa0e57d><div class="VPNavBar has-sidebar" data-v-0fa0e57d data-v-be450ad9><div class="container" data-v-be450ad9><div class="title" data-v-be450ad9><div class="VPNavBarTitle has-sidebar" data-v-be450ad9 data-v-6d2fb2d9><a class="title" href="/" data-v-6d2fb2d9><!--[--><!--]--><!----><!--[-->Lumiseven&#39;s blog<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-be450ad9><div class="curtain" data-v-be450ad9></div><div class="content-body" data-v-be450ad9><!--[--><!--]--><!----><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-be450ad9 data-v-bdedfc22><span id="main-nav-aria-label" class="visually-hidden" data-v-bdedfc22>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/doc/index" data-v-bdedfc22 data-v-f2ec7ecf data-v-a8b5c975><!--[-->Document<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/jotting/index" data-v-bdedfc22 data-v-f2ec7ecf data-v-a8b5c975><!--[-->Jotting<!--]--><!----></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-be450ad9 data-v-da3f667a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-da3f667a data-v-0d529b6d data-v-f3c41672><span class="check" data-v-f3c41672><span class="icon" data-v-f3c41672><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-0d529b6d><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-0d529b6d><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-be450ad9 data-v-2ab2a029 data-v-f6988cfb><!--[--><a class="VPSocialLink" href="https://github.com/lumiseven/" target="_blank" rel="noopener" data-v-f6988cfb data-v-e57698f6><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-be450ad9 data-v-66bb1f24 data-v-96001b6b><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-96001b6b><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-96001b6b><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-96001b6b><div class="VPMenu" data-v-96001b6b data-v-e7ea1737><!----><!--[--><!--[--><!----><div class="group" data-v-66bb1f24><div class="item appearance" data-v-66bb1f24><p class="label" data-v-66bb1f24>Appearance</p><div class="appearance-action" data-v-66bb1f24><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-66bb1f24 data-v-0d529b6d data-v-f3c41672><span class="check" data-v-f3c41672><span class="icon" data-v-f3c41672><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-0d529b6d><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-0d529b6d><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-66bb1f24><div class="item social-links" data-v-66bb1f24><div class="VPSocialLinks social-links-list" data-v-66bb1f24 data-v-f6988cfb><!--[--><a class="VPSocialLink" href="https://github.com/lumiseven/" target="_blank" rel="noopener" data-v-f6988cfb data-v-e57698f6><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-be450ad9 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav" data-v-93a960b4 data-v-2817d72e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-2817d72e><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-2817d72e><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-2817d72e>Menu</span></button><a class="top-link" href="#" data-v-2817d72e>Return to top</a></div><aside class="VPSidebar" data-v-93a960b4 data-v-c79ccefa><div class="curtain" data-v-c79ccefa></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-c79ccefa><span class="visually-hidden" id="sidebar-aria-label" data-v-c79ccefa> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>ML/DS/AI</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://wch.github.io/latexsheet/" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>latexsheet</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/common_math_formulas" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>基础数学公式</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/random_forest_model" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>随机森林模型</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/project" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Stable diffusion</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/vector_search_library" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>向量搜索库</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/ml_top_10_algorithms_advantages_disadvantages" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>机器学习十大常见算法的优缺点</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/simulated_annealing" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>simulated annealing</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible has-active" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>LLM</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><section class="VPSidebarItem level-1 collapsible is-link has-active" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/fine-tuning/_fine-tuning" data-v-983f6b21 data-v-a8b5c975><!--[--><h3 class="text" data-v-983f6b21>fine-tuning</h3><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-2 is-link is-active has-active" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/fine-tuning/llama3_fine-tuning" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>fine-tuning llama3+unsloth</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/fine-tuning/fine-tuning_vs_rag" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>fine-tuning vs RAG</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/fine-tuning/llama3_vs_gpt-4" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>llama3 vs gpt4</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/fine-tuning/llama3_fine-tuning_chinese" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>llama3 中文微调</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://www.promptingguide.ai/" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>prompt-engineering</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/ollama" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>ollama</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/llama3-groq-tool" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>llama3 groq tool-use</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/openai_api-mistral_api" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>OPENAI vs MISTRALAI</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/ai/llamaindex_text_to_sql" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>llama3 text to sql</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>JVM</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/jvm/javabase" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Java 基础</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://github.com/seven-org/jvm_readme/blob/master/Java%E6%96%B0%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D.md" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Java 新特性介绍(8~17)</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://github.com/seven-org/jvm_readme#jvm-%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E8%AF%A6%E8%A7%A3" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>JVM 内存布局详解</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/jvm/concurrency" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Java 并发编程</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/jvm/bean_copy" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Java bean_copy</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://github.com/seven-org/jvm_readme/tree/master/io#bionioaionetty" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>BIO、NIO、AIO、Netty</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/jvm/kotlin_corouties" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>kotlin coroutines</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/jvm/lock4j" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>lock4j</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/jvm/hippo4j" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>hippo4j</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/jvm/guava" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>guava</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/jvm/sentinel" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>sentinel</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/jvm/springboot_extension_1" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>springboot-extension</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>Python</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/python/python_3_12_new" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>3.12新功能</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/python/interpreter" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>python 编译器</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/python/multiprocessing" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>多线程 多进程</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>Database</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/rdb/mysqlquestion" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Mysql 常见问题</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/rdb/mysqloperation" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Mysql O&M</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/rdb/querybigdata" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Mysql 查询大量数据(流式查询)</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/rdb/mysqlfulltextsearch" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Mysql 全文索引</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/rdb/mysqlspatialindex" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Mysql 地理空间索引</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/rdb/mysqlvspostgres" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Mysql vs Postgres</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/rdb/uuid" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>DBA的角度谈UUID</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/rdb/mysql_5_7_to_8_0_tips" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>mysql5.7->8.0 升级tips</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>Cache</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://github.com/seven-org/redis_readme#%E7%BB%86%E8%AF%B4-redis-70-%E7%9A%84%E4%B9%9D%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>细说 Redis 7.0 的九种数据类型及应用场景</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://github.com/seven-org/redis_readme/blob/master/mysql-redis-cache-flush.md#mysqlredis%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>mysql,redis如何保证双写一致性</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://github.com/seven-org/redis_readme/blob/master/cache-strategy.md#redis%E7%9A%84%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E4%B8%8E%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>redis的删除策略与淘汰策略有什么区别</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://github.com/seven-org/redis_readme/blob/master/Redis-Lua.md#redis-%E4%B8%AD-lua-%E8%84%9A%E6%9C%AC%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%AE%9E%E8%B7%B5" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Redis 中 Lua 脚本的应用和实践</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/redis/bigkeys" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Redis bigKeys</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/redis/bitmap_user_sign" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Redis bitmap 用户登陆业务</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>Git</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/git/command" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Git 常用命令</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>Nginx</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/nginx/nginx" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Nginx</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/nginx/nginxvscaddy" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Nginx vs Caddy</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/nginx/caddy" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Caddy</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/nginx/haproxyandnginx" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>Haproxy + Nginx</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>Elasticsearch</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/es/index" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>ES</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://github.com/lumiseven/es-memo/blob/master/write_operation.md#es-%E7%9A%84%E5%86%99%E5%85%A5%E8%BF%87%E7%A8%8B" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>ES 的写入过程</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://github.com/lumiseven/es-memo/blob/master/http_operate.md#http-%E6%93%8D%E4%BD%9C" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>ES RESTAPI 操作 Demo</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/es/es_java" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>ES JAVA RESTAPI 操作 Demo</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/es/geo" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>ES geo</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/es/infrequentoperation" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>ES 不常用操作记录</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>Tools</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/tools/frp" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>frp</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-c79ccefa><section class="VPSidebarItem level-0 collapsible" data-v-c79ccefa data-v-983f6b21><div class="item" role="button" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link" data-v-983f6b21 data-v-a8b5c975><!--[--><h2 class="text" data-v-983f6b21>Others</h2><!--]--><!----></a><div class="caret" role="button" data-v-983f6b21><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-983f6b21><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-983f6b21><!--[--><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="https://gist.github.com/lumiseven/af46c3fb0f7d1865007912f8866d60ea" target="_blank" rel="noreferrer" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>正则表达式</p><!--]--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="icon" data-v-a8b5c975><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/others/http1_1_vs_http2" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>http1.1 vs http2</p><!--]--><!----></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-983f6b21 data-v-983f6b21><div class="item" data-v-983f6b21><div class="indicator" data-v-983f6b21></div><a class="VPLink link link" href="/doc/others/common_regular_expression" data-v-983f6b21 data-v-a8b5c975><!--[--><p class="text" data-v-983f6b21>常用正则</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-93a960b4 data-v-0bd490fb><div class="VPDoc has-sidebar has-aside" data-v-0bd490fb data-v-c5936a1e><div class="container" data-v-c5936a1e><div class="aside" data-v-c5936a1e><div class="aside-curtain" data-v-c5936a1e></div><div class="aside-container" data-v-c5936a1e><div class="aside-content" data-v-c5936a1e><div class="VPDocAside" data-v-c5936a1e data-v-cdc66372><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" data-v-cdc66372 data-v-5dd9d5f6><div class="content" data-v-5dd9d5f6><div class="outline-marker" data-v-5dd9d5f6></div><div class="outline-title" data-v-5dd9d5f6>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-5dd9d5f6><span class="visually-hidden" id="doc-outline-aria-label" data-v-5dd9d5f6> Table of Contents for current page </span><ul class="root" data-v-5dd9d5f6 data-v-1188541a><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-cdc66372></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-c5936a1e><div class="content-container" data-v-c5936a1e><!--[--><!--]--><main class="main" data-v-c5936a1e><div style="position:relative;" class="vp-doc _doc_ai_fine-tuning_llama3_fine-tuning" data-v-c5936a1e><div><h1 id="llama3-fine-tuning" tabindex="-1">Llama3 fine-tuning <a class="header-anchor" href="#llama3-fine-tuning" aria-hidden="true">#</a></h1><h2 id="为什么选择-llama3-进行微调" tabindex="-1">为什么选择 Llama3 进行微调 <a class="header-anchor" href="#为什么选择-llama3-进行微调" aria-hidden="true">#</a></h2><ol><li><strong>高精度</strong>：Llama3 在各种基准测试中表现出更加先进的准确性，包括 SuperGLUE、GLUE、SQuAD</li><li><strong>高效率</strong>：Llama3 经过优化，可以高效运行，即使是在资源有限的设备上也是如此。这意味着它可以用于各种实时应用程序</li><li><strong>泛化能力强</strong>：Llama3 能够泛化到与训练数据不同的数据，这意味着它可以用于各种新任务和域</li><li><strong>更灵活</strong>：Llama3 可以使用多种方法进行微调，这使其可用于各种任务</li></ol><h1 id="unsloth" tabindex="-1"><a href="https://github.com/unslothai/unsloth" target="_blank" rel="noreferrer">unsloth</a> <a class="header-anchor" href="#unsloth" aria-hidden="true">#</a></h1><p>Unsloth 是一个新兴的人工智能公司，专注于加快和优化大型语言模型（LLMs）的训练过程。传统上，LLMs的训练需要大量的计算资源和内存，耗时较长。为了解决这一问题，Unsloth 开发了一款名为 Unsloth 的软件，能够将训练速度提升高达30倍，并将内存使用减少60%。</p><h2 id="unsloth-主要特点和优势" tabindex="-1">unsloth 主要特点和优势： <a class="header-anchor" href="#unsloth-主要特点和优势" aria-hidden="true">#</a></h2><p>通过 QLoRA 和 LoRA 技术来加速 LLM 的微调，能够提升 2-5 倍的性能并减少 70% 的内存使用量</p><ol><li><p><strong>技术优化</strong>：</p><ul><li><strong>手动自动微分（Manual Autograd）</strong>：通过手动计算梯度来优化模型更新过程，加快训练速度。</li><li><strong>链式矩阵乘法（Chained Matrix Multiplication）</strong>：高效地优化矩阵乘法，是LLMs训练中的关键步骤。</li><li><strong>Triton语言内核（Triton Language Kernels）</strong>：使用由OpenAI开发的高性能计算语言 Triton 重写关键训练代码。</li><li><strong>Flash Attention</strong>：通过 xformers 和 Tri Dao 的实现，帮助模型集中注意力于输入数据的重要部分。</li></ul></li><li><p><strong>工作原理</strong></p><ul><li>通过将 LLM 的权重分解为低秩矩阵来减少内存使用量</li><li>能够在更小的 GPU 上训练 LLM，或者在更大的 GPU 上训练更大的 LLM</li><li>可以有效地加速各种 LLM 的微调，包括 GPT-3 Jurassic-1 Jumbo 和 Megatron-Turing NLG</li></ul></li><li><p><strong>兼容性和可访问性</strong>：</p><ul><li>支持 NVIDIA、Intel 和 AMD 等主流GPU，无需购买昂贵的新硬件即可使用。</li><li>提供免费的开源版本，任何人都可以在GitHub上获取并体验快速训练和更少内存使用的好处。</li></ul></li><li><p><strong>适用场景</strong>：</p><ul><li>NLP</li><li>机器翻译</li><li>文本生成</li><li>问答系统</li><li>聊天机器人</li></ul></li><li><p><strong>支持的语言模型</strong>：</p><ul><li>支持多种流行的语言模型，使用户可以轻松应用优化技术到其喜爱的模型上。</li></ul></li><li><p><strong>性能测试结果</strong>：</p><ul><li>在多个数据集和硬件设置下，Unsloth 显著减少了训练时间和内存使用量，例如在 Alpaca 数据集上，将训练时间从85小时缩短到仅3小时，内存使用从16.7GB降至6.9GB。</li></ul></li><li><p><strong>社区和未来计划</strong>：</p><ul><li>积极与AI社区互动，鼓励用户尝试其开源软件并提供反馈。</li><li>提供Pro和Max版本，支持多GPU和完整的LLM训练功能。</li><li>未来计划包括进一步增加推理速度、实施 sqrt 梯度检查点技术以进一步减少内存使用、优化训练方法等。</li></ul></li><li><p><strong>结论</strong>：</p><ul><li>Unsloth 在加快和优化AI语言模型训练方面取得了显著进展。他们的技术不仅提高了训练效率，还通过兼容性、可访问性和社区参与，致力于在AI和自然语言处理领域产生深远影响。</li></ul></li></ol><p>这些特点使得 Unsloth 成为当前AI领域中备受关注的技术创新之一。</p><h1 id="具体实现" tabindex="-1">具体实现 <a class="header-anchor" href="#具体实现" aria-hidden="true">#</a></h1><p><a href="https://colab.research.google.com/drive/12YnUcuS640v78N75lw_ydmbuJXrLvMYn#scrollTo=iHjt_SMYsd3P" target="_blank" rel="noreferrer">colab</a></p><ol><li>安装 unsloth</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676E95;font-style:italic;"># Installs Unsloth, Xformers (Flash Attention) and all other packages!</span></span>
<span class="line"><span style="color:#A6ACCD;">!pip install </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git</span><span style="color:#89DDFF;">&quot;</span></span>
<span class="line"><span style="color:#A6ACCD;">!pip install --no</span><span style="color:#89DDFF;">-</span><span style="color:#A6ACCD;">deps xformers </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">trl&lt;0.9.0</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;"> peft accelerate bitsandbytes</span></span>
<span class="line"></span></code></pre></div><ol start="2"><li>加载模型</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> unsloth </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> FastLanguageModel</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> torch</span></span>
<span class="line"><span style="color:#A6ACCD;">max_seq_length </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">2048</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Choose any! We auto support RoPE Scaling internally!</span></span>
<span class="line"><span style="color:#A6ACCD;">dtype </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">None</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+</span></span>
<span class="line"><span style="color:#A6ACCD;">load_in_4bit </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">True</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Use 4bit quantization to reduce memory usage. Can be False.</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 4bit pre quantized models we support for 4x faster downloading + no OOMs.</span></span>
<span class="line"><span style="color:#A6ACCD;">fourbit_models </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/mistral-7b-v0.3-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">      </span><span style="color:#676E95;font-style:italic;"># New Mistral v3 2x faster!</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/mistral-7b-instruct-v0.3-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/llama-3-8b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">           </span><span style="color:#676E95;font-style:italic;"># Llama-3 15 trillion tokens model 2x faster!</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/llama-3-8b-Instruct-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/llama-3-70b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/Phi-3-mini-4k-instruct</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># Phi-3 2x faster!</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/Phi-3-medium-4k-instruct</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/mistral-7b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/gemma-7b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">             </span><span style="color:#676E95;font-style:italic;"># Gemma 2.2x faster!</span></span>
<span class="line"><span style="color:#89DDFF;">]</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># More models at https://huggingface.co/unsloth</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">model</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> tokenizer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">from_pretrained</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">model_name</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/llama-3-8b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">max_seq_length</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> max_seq_length</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">dtype</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> dtype</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">load_in_4bit</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> load_in_4bit</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#676E95;font-style:italic;"># token = &quot;hf_...&quot;, # use one if using gated models like meta-llama/Llama-2-7b-hf</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><ol start="3"><li>修改模型 结合 QLoRA/LoRA 配置优化微调参数</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#A6ACCD;">model </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">get_peft_model</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    model</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">r</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">16</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># Choose any number &gt; 0 ! Suggested 8, 16, 32, 64, 128</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">target_modules</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">q_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">k_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">v_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">o_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">                      </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">gate_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">up_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">down_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,],</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">lora_alpha</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">16</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">lora_dropout</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># Supports any, but = 0 is optimized</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">bias</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">none</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;">    </span><span style="color:#676E95;font-style:italic;"># Supports any, but = &quot;none&quot; is optimized</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#676E95;font-style:italic;"># [NEW] &quot;unsloth&quot; uses 30% less VRAM, fits 2x larger batch sizes!</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">use_gradient_checkpointing</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># True or &quot;unsloth&quot; for very long context</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">random_state</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3407</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">use_rslora</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">False,</span><span style="color:#82AAFF;">  </span><span style="color:#676E95;font-style:italic;"># We support rank stabilized LoRA</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">loftq_config</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">None,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># And LoftQ</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><ol start="4"><li>加载并构造 train-data</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#A6ACCD;">alpaca_prompt </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;&quot;&quot;</span><span style="color:#C3E88D;">Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C3E88D;">### Instruction:</span></span>
<span class="line"><span style="color:#F78C6C;">{}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C3E88D;">### Input:</span></span>
<span class="line"><span style="color:#F78C6C;">{}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C3E88D;">### Response:</span></span>
<span class="line"><span style="color:#F78C6C;">{}</span><span style="color:#89DDFF;">&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">EOS_TOKEN </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> tokenizer</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">eos_token</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Must add EOS_TOKEN</span></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">formatting_prompts_func</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">examples</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    instructions </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> examples</span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">instruction</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#A6ACCD;">    inputs       </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> examples</span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">input</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#A6ACCD;">    outputs      </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> examples</span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">output</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#A6ACCD;">    texts </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[]</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">for</span><span style="color:#A6ACCD;"> instruction</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">input</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> output </span><span style="color:#89DDFF;font-style:italic;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">zip</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">instructions</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> inputs</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> outputs</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># Must add EOS_TOKEN, otherwise your generation will go on forever!</span></span>
<span class="line"><span style="color:#A6ACCD;">        text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> alpaca_prompt</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">format</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">instruction</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> input</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> output</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">+</span><span style="color:#A6ACCD;"> EOS_TOKEN</span></span>
<span class="line"><span style="color:#A6ACCD;">        texts</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">append</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">text</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">text</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> texts</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> datasets </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> load_dataset</span></span>
<span class="line"><span style="color:#A6ACCD;">dataset </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">load_dataset</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">yahma/alpaca-cleaned</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">split</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">train</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">dataset </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> dataset</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">map</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">formatting_prompts_func</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">batched</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">True,)</span></span>
<span class="line"></span></code></pre></div><ol start="5"><li>训练模型配置</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> trl </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> SFTTrainer</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> transformers </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> TrainingArguments</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> unsloth </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> is_bfloat16_supported</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">trainer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">SFTTrainer</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">model</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> model</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">tokenizer</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">train_dataset</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> dataset</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">dataset_text_field</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">text</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">max_seq_length</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> max_seq_length</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">dataset_num_proc</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">2</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">packing</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">False,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># Can make training 5x faster for short sequences.</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">args</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> TrainingArguments</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">per_device_train_batch_size</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">2</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">gradient_accumulation_steps</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">4</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">warmup_steps</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">5</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">max_steps</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">60</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">learning_rate</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">2e-4</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">fp16</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;font-style:italic;">not</span><span style="color:#82AAFF;"> is_bfloat16_supported</span><span style="color:#89DDFF;">(),</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">bf16</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> is_bfloat16_supported</span><span style="color:#89DDFF;">(),</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">logging_steps</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">optim</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">adamw_8bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">weight_decay</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">0.01</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">lr_scheduler_type</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">linear</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">seed</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3407</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">output_dir</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">outputs</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">),</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><ol start="6"><li>[Optional]显示当前memory状态[对比内存占用]</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676E95;font-style:italic;">#@title Show current memory stats</span></span>
<span class="line"><span style="color:#A6ACCD;">gpu_stats </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">cuda</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">get_device_properties</span><span style="color:#89DDFF;">(</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">start_gpu_memory </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">round</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">cuda</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">max_memory_reserved</span><span style="color:#89DDFF;">()</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1024</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1024</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1024</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">max_memory </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">round</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">gpu_stats</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">total_memory</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1024</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1024</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1024</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;GPU = </span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">gpu_stats</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">name</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;">. Max memory = </span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">max_memory</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> GB.&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;</span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">start_gpu_memory</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> GB of memory reserved.&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><ol start="7"><li>实际执行训练</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#A6ACCD;">trainer_stats </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> trainer</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">train</span><span style="color:#89DDFF;">()</span></span>
<span class="line"></span></code></pre></div><ol start="8"><li>[Optional]显示当前memory状态[对比内存占用]</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676E95;font-style:italic;">#@title Show final memory and time stats</span></span>
<span class="line"><span style="color:#A6ACCD;">used_memory </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">round</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">cuda</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">max_memory_reserved</span><span style="color:#89DDFF;">()</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1024</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1024</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1024</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">used_memory_for_lora </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">round</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">used_memory </span><span style="color:#89DDFF;">-</span><span style="color:#82AAFF;"> start_gpu_memory</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">used_percentage </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">round</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">used_memory         </span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;">max_memory</span><span style="color:#89DDFF;">*</span><span style="color:#F78C6C;">100</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">lora_percentage </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">round</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">used_memory_for_lora</span><span style="color:#89DDFF;">/</span><span style="color:#82AAFF;">max_memory</span><span style="color:#89DDFF;">*</span><span style="color:#F78C6C;">100</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;</span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">trainer_stats</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">metrics</span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">train_runtime</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">]</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> seconds used for training.&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;</span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">round</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">trainer_stats</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">metrics</span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">train_runtime</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">]/</span><span style="color:#F78C6C;">60</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">2</span><span style="color:#89DDFF;">)</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> minutes used for training.&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;Peak reserved memory = </span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">used_memory</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> GB.&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;Peak reserved memory for training = </span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">used_memory_for_lora</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> GB.&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;Peak reserved memory % of max memory = </span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">used_percentage</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> %.&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;Peak reserved memory for training % of max memory = </span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">lora_percentage</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> %.&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><ol start="9"><li>完成后执行推理</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676E95;font-style:italic;"># alpaca_prompt = Copied from above</span></span>
<span class="line"><span style="color:#A6ACCD;">FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">for_inference</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Enable native 2x faster inference</span></span>
<span class="line"><span style="color:#A6ACCD;">inputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">tokenizer</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#82AAFF;">    alpaca_prompt</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">format</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Continue the fibonnaci sequence.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># instruction</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">1, 1, 2, 3, 5, 8</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># input</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># output - leave this blank for generation!</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#89DDFF;">],</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">return_tensors</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">pt</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">to</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">cuda</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">outputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">generate</span><span style="color:#89DDFF;">(**</span><span style="color:#82AAFF;">inputs</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">max_new_tokens</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">64</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">use_cache</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">True)</span></span>
<span class="line"><span style="color:#A6ACCD;">tokenizer</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">batch_decode</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">outputs</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><p><code>stream</code>形式</p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676E95;font-style:italic;"># alpaca_prompt = Copied from above</span></span>
<span class="line"><span style="color:#A6ACCD;">FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">for_inference</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Enable native 2x faster inference</span></span>
<span class="line"><span style="color:#A6ACCD;">inputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">tokenizer</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#82AAFF;">    alpaca_prompt</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">format</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Continue the fibonnaci sequence.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># instruction</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">1, 1, 2, 3, 5, 8</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># input</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># output - leave this blank for generation!</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#89DDFF;">],</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">return_tensors</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">pt</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">to</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">cuda</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> transformers </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> TextStreamer</span></span>
<span class="line"><span style="color:#A6ACCD;">text_streamer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">TextStreamer</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">tokenizer</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">_ </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">generate</span><span style="color:#89DDFF;">(**</span><span style="color:#82AAFF;">inputs</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">streamer</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> text_streamer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">max_new_tokens</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">128</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><ol start="10"><li>保存模型</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#A6ACCD;">model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save_pretrained</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lora_model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Local saving</span></span>
<span class="line"><span style="color:#A6ACCD;">tokenizer</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save_pretrained</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lora_model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># model.push_to_hub(&quot;your_name/lora_model&quot;, token = &quot;...&quot;) # Online saving</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># tokenizer.push_to_hub(&quot;your_name/lora_model&quot;, token = &quot;...&quot;) # Online saving</span></span>
<span class="line"></span></code></pre></div><ol start="11"><li>unsloth加载模型</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> unsloth </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> FastLanguageModel</span></span>
<span class="line"><span style="color:#A6ACCD;">    model</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> tokenizer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">from_pretrained</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">model_name</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lora_model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># YOUR MODEL YOU USED FOR TRAINING</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">max_seq_length</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> max_seq_length</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">dtype</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> dtype</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">load_in_4bit</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> load_in_4bit</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">for_inference</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Enable native 2x faster inference</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># alpaca_prompt = You MUST copy from above!</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">inputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">tokenizer</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#82AAFF;">    alpaca_prompt</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">format</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">What is a famous tall tower in Paris?</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># instruction</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># input</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># output - leave this blank for generation!</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#89DDFF;">],</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">return_tensors</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">pt</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">to</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">cuda</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">outputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">generate</span><span style="color:#89DDFF;">(**</span><span style="color:#82AAFF;">inputs</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">max_new_tokens</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">64</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">use_cache</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">True)</span></span>
<span class="line"><span style="color:#A6ACCD;">tokenizer</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">batch_decode</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">outputs</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><ol start="12"><li>hf加载模型</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># I highly do NOT suggest - use Unsloth if possible</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> peft </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> AutoPeftModelForCausalLM</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> transformers </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> AutoTokenizer</span></span>
<span class="line"><span style="color:#A6ACCD;">    model </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> AutoPeftModelForCausalLM</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">from_pretrained</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lora_model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># YOUR MODEL YOU USED FOR TRAINING</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">load_in_4bit</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> load_in_4bit</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    tokenizer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> AutoTokenizer</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">from_pretrained</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lora_model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><ol start="13"><li>保存为VLLM float16</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676E95;font-style:italic;"># Merge to 16bit</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">True:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save_pretrained_merged</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">llama-3-8b-bnb-4bit-ft-1</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">save_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">merged_16bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,)</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">True:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">push_to_hub_merged</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lumiseven/llama-3-8b-bnb-4bit-ft-1</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">save_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">merged_16bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">token</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># Merge to 4bit</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save_pretrained_merged</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">llama-3-8b-bnb-4bit-ft-1</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">save_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">merged_4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,)</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">push_to_hub_merged</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lumiseven/llama-3-8b-bnb-4bit-ft-1</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">save_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">merged_4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">token</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># Just LoRA adapters</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save_pretrained_merged</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">save_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lora</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,)</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">push_to_hub_merged</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">hf/model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">save_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lora</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">token</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><ol start="14"><li>GGUF/llama.cpp 转换</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676E95;font-style:italic;"># Save to 8bit Q8_0</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save_pretrained_gguf</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,)</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">push_to_hub_gguf</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">hf/model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">token</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># Save to 16bit GGUF</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save_pretrained_gguf</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">quantization_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">f16</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">push_to_hub_gguf</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">hf/model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">quantization_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">f16</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">token</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># Save to q4_k_m GGUF</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save_pretrained_gguf</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">quantization_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">q4_k_m</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">False:</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">push_to_hub_gguf</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">hf/model</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">quantization_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">q4_k_m</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">token</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div></div></div></main><!--[--><!--]--><footer class="VPDocFooter" data-v-c5936a1e data-v-2813752b><div class="edit-info" data-v-2813752b><div class="edit-link" data-v-2813752b><span class="VPLink edit-link-button" data-v-2813752b data-v-a8b5c975><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="edit-link-icon" data-v-2813752b><path d="M18,23H4c-1.7,0-3-1.3-3-3V6c0-1.7,1.3-3,3-3h7c0.6,0,1,0.4,1,1s-0.4,1-1,1H4C3.4,5,3,5.4,3,6v14c0,0.6,0.4,1,1,1h14c0.6,0,1-0.4,1-1v-7c0-0.6,0.4-1,1-1s1,0.4,1,1v7C21,21.7,19.7,23,18,23z"></path><path d="M8,17c-0.3,0-0.5-0.1-0.7-0.3C7,16.5,6.9,16.1,7,15.8l1-4c0-0.2,0.1-0.3,0.3-0.5l9.5-9.5c1.2-1.2,3.2-1.2,4.4,0c1.2,1.2,1.2,3.2,0,4.4l-9.5,9.5c-0.1,0.1-0.3,0.2-0.5,0.3l-4,1C8.2,17,8.1,17,8,17zM9.9,12.5l-0.5,2.1l2.1-0.5l9.3-9.3c0.4-0.4,0.4-1.1,0-1.6c-0.4-0.4-1.2-0.4-1.6,0l0,0L9.9,12.5z M18.5,2.5L18.5,2.5L18.5,2.5z"></path></svg> Edit this page on GitHub<!--]--><!----></span></div><div class="last-updated" data-v-2813752b><p class="VPLastUpdated" data-v-2813752b data-v-355aa5ef>Last updated: <time datetime="2024-07-07T01:15:09.000Z" data-v-355aa5ef></time></p></div></div><div class="prev-next" data-v-2813752b><div class="pager" data-v-2813752b><a class="pager-link prev" href="/doc/ai/fine-tuning/_fine-tuning" data-v-2813752b><span class="desc" data-v-2813752b>Previous page</span><span class="title" data-v-2813752b>fine-tuning</span></a></div><div class="has-prev pager" data-v-2813752b><a class="pager-link next" href="/doc/ai/fine-tuning/fine-tuning_vs_rag" data-v-2813752b><span class="desc" data-v-2813752b>Next page</span><span class="title" data-v-2813752b>fine-tuning vs RAG</span></a></div></div></footer><!--[--><!--]--></div></div></div></div></div><footer class="VPFooter has-sidebar" data-v-93a960b4 data-v-d24360a6><div class="container" data-v-d24360a6><p class="message" data-v-d24360a6>Released under the MIT License.</p><p class="copyright" data-v-d24360a6>Copyright © 2015-present Lumiseven</p></div></footer><!--[--><!--]--></div></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"doc_ai_fine-tuning_fine-tuning_vs_rag.md\":\"5b7c2843\",\"about_index.md\":\"236813ed\",\"doc_ai_chatgpt_embdding.md\":\"c9a14581\",\"doc_ai_fine-tuning__fine-tuning.md\":\"77f54139\",\"about_about_me.md\":\"3ec180a4\",\"doc_ai_common_math_formulas.md\":\"d89f484a\",\"doc_ai_langflow.md\":\"1ad90608\",\"doc_ai_fine-tuning_phi3_fine-tuning.md\":\"fe008782\",\"doc_ai_fine-tuning_llama3_fine-tuning.md\":\"be2d117c\",\"doc_ai_fine-tuning_llama3_vs_gpt-4.md\":\"5138cd1f\",\"doc_ai_fine-tuning_llama3_fine-tuning_chinese.md\":\"0cbeba05\",\"doc_ai_ml_top_10_algorithms_advantages_disadvantages.md\":\"6519a5eb\",\"doc_ai_vector_search_library.md\":\"ff2bd009\",\"doc_ai_random_forest_model.md\":\"d8bf041d\",\"doc_ai_simulated_annealing.md\":\"54ec38e2\",\"doc_ai_llamaindex_text_to_sql.md\":\"03e9d8e2\",\"jotting_1677990878.md\":\"080e67db\",\"jotting_1678330412.md\":\"71125517\",\"jotting_1678891164.md\":\"d7ad7996\",\"jotting_1678937136.md\":\"547e9940\",\"jotting_1680498848.md\":\"04b9a2e3\",\"jotting_1682611195.md\":\"d4fa6349\",\"jotting_es_tmp_1.md\":\"fd1a2521\",\"jotting_numpy_csv_executable.md\":\"6159ef6a\",\"jotting_python_calculate_derivative.md\":\"12882f14\",\"jotting_python_generate_qrcode.md\":\"0c6d9a16\",\"jotting_python_port_scanner.md\":\"c742c57d\",\"jotting_python_remove_image_background.md\":\"0d43bc62\",\"jotting_resume.md\":\"685227f9\",\"jotting_springboot_make_blog_api.md\":\"1575e324\",\"doc_tools_frp.md\":\"692a0aa2\",\"doc_index.md\":\"ffa96f6c\",\"doc_jvm_javabase.md\":\"dac01dcb\",\"doc_jvm_kotlin_corouties.md\":\"e0695f5c\",\"doc_jvm_lock4j.md\":\"8e6fe0ec\",\"doc_jvm_sentinel.md\":\"bc4e8886\",\"doc_jvm_springboot_extension_1.md\":\"65dbf222\",\"doc_nginx_haproxyandnginx.md\":\"25868650\",\"doc_es_geo.md\":\"d5d0d4ee\",\"doc_jvm_coroutines.md\":\"fa9409af\",\"doc_jvm_concurrency.md\":\"00c5c1da\",\"doc_redis_bigkeys.md\":\"80850772\",\"doc_others_common_heartbeat_detection_algorithms.md\":\"25ce1662\",\"doc_others_common_regular_expression.md\":\"a08a72cb\",\"doc_others_http1_1_vs_http2.md\":\"43b4edf0\",\"doc_python_interpreter.md\":\"e5e5e6ac\",\"doc_python_multiprocessing.md\":\"671be89f\",\"doc_python_python_3_12_new.md\":\"eb6e26d8\",\"doc_rdb_mysql_5_7_to_8_0_tips.md\":\"be34e367\",\"doc_rdb_mysqlfulltextsearch.md\":\"6e8d83f5\",\"doc_rdb_mysqloperation.md\":\"69e7814a\",\"doc_rdb_mysqlquestion.md\":\"fed8440f\",\"doc_rdb_mysqlspatialindex.md\":\"1ddb5bde\",\"doc_ai_ollama.md\":\"fa703302\",\"doc_rdb_querybigdata.md\":\"be57dd88\",\"doc_rdb_uuid.md\":\"87029002\",\"doc_nginx_nginx.md\":\"a3d1bfcc\",\"doc_ai_pixtral_12b_video.md\":\"30095d94\",\"jotting_index.md\":\"aaea502a\",\"doc_rdb_mysqlvspostgres.md\":\"9a464ea7\",\"doc_ai_openai_api-mistral_api.md\":\"9263d2b4\",\"doc_es_index.md\":\"09f95297\",\"doc_ai_project.md\":\"540da7df\",\"doc_ai_prompt-engineering__prompt-engineering.md\":\"98a256db\",\"doc_redis_bitmap_user_sign.md\":\"ad803939\",\"index.md\":\"124cd647\",\"doc_ai_llama3-groq-tool.md\":\"6fd22ca6\",\"doc_jvm_concurrency2.md\":\"50a0470d\",\"doc_jvm_guava.md\":\"4cbcc629\",\"doc_es_infrequentoperation.md\":\"649300b6\",\"doc_es_es_java.md\":\"35f5ba93\",\"doc_jvm_bean_copy.md\":\"d34820a7\",\"doc_git_command.md\":\"37be0e6e\",\"doc_jvm_hippo4j.md\":\"248699e4\",\"doc_nginx_caddy.md\":\"fffe4abc\",\"doc_nginx_nginxvscaddy.md\":\"d35499a3\"}")</script>
    <script type="module" async src="/assets/app.413235d3.js"></script>
    
  </body>
</html>