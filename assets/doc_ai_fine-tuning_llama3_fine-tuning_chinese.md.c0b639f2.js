import{_ as s,c as n,o as a,b as l}from"./app.c314d56e.js";const C=JSON.parse('{"title":"适用中文的 llama3 微调","description":"","frontmatter":{},"headers":[],"relativePath":"doc/ai/fine-tuning/llama3_fine-tuning_chinese.md","lastUpdated":1720515362000}'),o={name:"doc/ai/fine-tuning/llama3_fine-tuning_chinese.md"},p=l(`<h1 id="适用中文的-llama3-微调" tabindex="-1">适用中文的 llama3 微调 <a class="header-anchor" href="#适用中文的-llama3-微调" aria-hidden="true">#</a></h1><h2 id="常用的中文数据集" tabindex="-1">常用的中文数据集 <a class="header-anchor" href="#常用的中文数据集" aria-hidden="true">#</a></h2><table><thead><tr><th>中文微调数据集</th><th>介绍</th></tr></thead><tbody><tr><td>COIG</td><td>中国开放式教学通才项目</td></tr><tr><td>Stanford Alpaca (Chinese)</td><td>Alpaca 数据集中文翻译（ChatGPT 辅助翻译）</td></tr><tr><td>BELLE</td><td>BELLE 项目的中文数据集（ChatGPT 生成）</td></tr><tr><td>GuanacoDataset</td><td>Guanaco 模型的对话数据集</td></tr><tr><td>WebQA(zh)</td><td>中文网络问答</td></tr><tr><td>pCLUE</td><td>基于提示的大规模预训练数据集，用于多任务学习和零样本学习</td></tr></tbody></table><hr><h2 id="指令微调" tabindex="-1">指令微调 <a class="header-anchor" href="#指令微调" aria-hidden="true">#</a></h2><p>指令微调（Instruction Fine-Tuning）是指在机器学习中，特别是在自然语言处理领域中，一种通过精细调整预训练模型的技术方法。通常情况下，预训练模型（如BERT、GPT等）在大规模语料上进行了泛化的学习，以学习语言的通用表示。然后，指令微调通过在特定任务上进行进一步的训练来优化模型的性能，使其适应特定任务的要求。</p><p>具体来说，指令微调的步骤包括以下几个方面：</p><ol><li><p><strong>选择预训练模型：</strong> 从已经经过大规模训练的模型中选择一个合适的基础模型，如BERT、GPT等。</p></li><li><p><strong>定义任务和数据集：</strong> 确定你想要在模型上执行的具体任务，并准备好相应的训练数据集。这些任务可以是分类、命名实体识别、文本生成等。</p></li><li><p><strong>微调模型：</strong> 将选定的预训练模型加载到环境中，并使用任务特定的数据集进行进一步的训练。在这个过程中，模型会调整它的权重和参数，以最大程度地提高在特定任务上的性能。</p></li><li><p><strong>评估和优化：</strong> 训练完成后，对微调后的模型进行评估，通常使用验证集来测量其在任务上的准确性和性能。根据评估结果，可能需要调整训练策略或进行进一步的优化。</p></li></ol><p>指令微调在性能和任务泛化性上的表现有以下几个关键点可以讨论：</p><ol><li><p><strong>性能提升：</strong></p><ul><li><strong>任务特定性能：</strong> 指令微调可以显著提高模型在特定任务上的性能。通过在任务特定数据集上进行微调，模型可以学习到更适合解决该任务的特征表示。例如，对于文本分类任务，微调后的模型可以更准确地区分不同的类别。</li><li><strong>精细调整能力：</strong> 微调允许对模型进行精细调整，使其在特定任务上表现更加优越。这种精细调整可以包括调整模型的权重、学习率等参数，以最大程度地优化任务的性能。</li></ul></li><li><p><strong>任务泛化性：</strong></p><ul><li><strong>泛化能力保持：</strong> 虽然微调是针对特定任务进行的优化，但良好的预训练模型通常能够保持其在其他任务上的泛化能力。这意味着，即使在进行了微调后，模型仍然可以处理不同但相关的任务，而无需重新训练。</li><li><strong>迁移学习效果：</strong> 指令微调的另一个优势是其在迁移学习方面的表现。通过利用预训练模型已经学到的通用语言特征，微调可以更快速地适应新的任务和数据集，从而提高效率和性能。</li></ul></li><li><p><strong>模型适应性和灵活性：</strong></p><ul><li><strong>适应特定场景：</strong> 微调允许根据实际应用需求调整模型，使其能够在特定领域或应用场景中发挥最佳效果。这种灵活性使得模型可以应对不同复杂度和需求的任务。</li><li><strong>模型更新和优化：</strong> 通过不断进行微调，可以使模型保持与新数据和新任务的适应性。这种持续优化的过程有助于模型在长期应用中保持竞争优势。</li></ul></li></ol><p>综上所述，指令微调通过在预训练模型基础上的精细调整，既能够显著提升模型在特定任务上的性能，又能够保持模型在其他任务上的泛化能力和适应性，从而成为当前自然语言处理任务中重要的优化方法之一。</p><h2 id="常用指令微调数据集格式" tabindex="-1">常用指令微调数据集格式 <a class="header-anchor" href="#常用指令微调数据集格式" aria-hidden="true">#</a></h2><div class="language-json"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C792EA;">instruction</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C792EA;">input</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C792EA;">output</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;&quot;</span></span>
<span class="line"><span style="color:#89DDFF;">}</span></span>
<span class="line"></span></code></pre></div><hr><h2 id="对话微调" tabindex="-1">对话微调 <a class="header-anchor" href="#对话微调" aria-hidden="true">#</a></h2><p>对话微调是指令微调的一种形式，它专注于提升大语言模型的对话处理能力。</p><p>这种方法不仅增强了模型的补全能力，还赋予了模型进行有效对话的能力。</p><p>在对话微调中，数据集通常包含指令、输入、输出及对话历史等元素，</p><p>保持与模型预训练和微调时的格式一致，</p><p>确保模型在实际应用中的效果与训练时相匹配。</p><h2 id="对话微调常用数据集格式" tabindex="-1">对话微调常用数据集格式 <a class="header-anchor" href="#对话微调常用数据集格式" aria-hidden="true">#</a></h2><div class="language-json"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C792EA;">instruction</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C792EA;">input</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C792EA;">output</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C792EA;">history</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">&quot;</span><span style="color:#FFCB6B;">speaker</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">用户</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">&quot;</span><span style="color:#FFCB6B;">utterance</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">&quot;</span><span style="color:#FFCB6B;">speaker</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">模型</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">&quot;</span><span style="color:#FFCB6B;">utterance</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">&quot;</span><span style="color:#FFCB6B;">speaker</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">用户</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">&quot;</span><span style="color:#FFCB6B;">utterance</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">&quot;</span><span style="color:#FFCB6B;">speaker</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">模型</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">&quot;</span><span style="color:#FFCB6B;">utterance</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#89DDFF;">}</span></span>
<span class="line"></span></code></pre></div><h2 id="使用中文数据集" tabindex="-1">使用中文数据集 <a class="header-anchor" href="#使用中文数据集" aria-hidden="true">#</a></h2><p><code>shibing624/alpaca-zh</code></p><h2 id="加载中文数据集" tabindex="-1">加载中文数据集 <a class="header-anchor" href="#加载中文数据集" aria-hidden="true">#</a></h2><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> datasets </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> load_dataset</span></span>
<span class="line"><span style="color:#A6ACCD;">dataset </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">load_dataset</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">shibing624/alpaca-zh</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">split</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">train</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div><h2 id="中文数据训练" tabindex="-1">中文数据训练 <a class="header-anchor" href="#中文数据训练" aria-hidden="true">#</a></h2><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#A6ACCD;">%%</span><span style="color:#FFCB6B;">capture</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># Installs Unsloth, Xformers (Flash Attention) and all other packages!</span></span>
<span class="line"><span style="color:#89DDFF;">!</span><span style="color:#FFCB6B;">pip</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">install</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git</span><span style="color:#89DDFF;">&quot;</span></span>
<span class="line"><span style="color:#89DDFF;">!</span><span style="color:#FFCB6B;">pip</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">install</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--no-deps</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">xformers</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">trl&lt;0.9.0</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">peft</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">accelerate</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">bitsandbytes</span></span>
<span class="line"></span></code></pre></div><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> unsloth </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> FastLanguageModel</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> torch</span></span>
<span class="line"><span style="color:#A6ACCD;">max_seq_length </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">2048</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Choose any! We auto support RoPE Scaling internally!</span></span>
<span class="line"><span style="color:#A6ACCD;">dtype </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">None</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+</span></span>
<span class="line"><span style="color:#A6ACCD;">load_in_4bit </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">True</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Use 4bit quantization to reduce memory usage. Can be False.</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 4bit pre quantized models we support for 4x faster downloading + no OOMs.</span></span>
<span class="line"><span style="color:#A6ACCD;">fourbit_models </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/mistral-7b-v0.3-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">      </span><span style="color:#676E95;font-style:italic;"># New Mistral v3 2x faster!</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/mistral-7b-instruct-v0.3-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/llama-3-8b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">           </span><span style="color:#676E95;font-style:italic;"># Llama-3 15 trillion tokens model 2x faster!</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/llama-3-8b-Instruct-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/llama-3-70b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/Phi-3-mini-4k-instruct</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># Phi-3 2x faster!</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/Phi-3-medium-4k-instruct</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/mistral-7b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/gemma-7b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;">             </span><span style="color:#676E95;font-style:italic;"># Gemma 2.2x faster!</span></span>
<span class="line"><span style="color:#89DDFF;">]</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># More models at https://huggingface.co/unsloth</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">model</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> tokenizer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">from_pretrained</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">model_name</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth/llama-3-8b-bnb-4bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">max_seq_length</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> max_seq_length</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">dtype</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> dtype</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">load_in_4bit</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> load_in_4bit</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#676E95;font-style:italic;"># token = &quot;hf_...&quot;, # use one if using gated models like meta-llama/Llama-2-7b-hf</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">model </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> FastLanguageModel</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">get_peft_model</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    model</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">r</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">16</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># Choose any number &gt; 0 ! Suggested 8, 16, 32, 64, 128</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">target_modules</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">q_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">k_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">v_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">o_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">                      </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">gate_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">up_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">down_proj</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,],</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">lora_alpha</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">16</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">lora_dropout</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># Supports any, but = 0 is optimized</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">bias</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">none</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;">    </span><span style="color:#676E95;font-style:italic;"># Supports any, but = &quot;none&quot; is optimized</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#676E95;font-style:italic;"># [NEW] &quot;unsloth&quot; uses 30% less VRAM, fits 2x larger batch sizes!</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">use_gradient_checkpointing</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">unsloth</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># True or &quot;unsloth&quot; for very long context</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">random_state</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3407</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">use_rslora</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">False,</span><span style="color:#82AAFF;">  </span><span style="color:#676E95;font-style:italic;"># We support rank stabilized LoRA</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">loftq_config</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">None,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># And LoftQ</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">alpaca_prompt </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;&quot;&quot;</span><span style="color:#C3E88D;">Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C3E88D;">### Instruction:</span></span>
<span class="line"><span style="color:#F78C6C;">{}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C3E88D;">### Input:</span></span>
<span class="line"><span style="color:#F78C6C;">{}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C3E88D;">### Response:</span></span>
<span class="line"><span style="color:#F78C6C;">{}</span><span style="color:#89DDFF;">&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">EOS_TOKEN </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> tokenizer</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">eos_token</span><span style="color:#A6ACCD;"> </span><span style="color:#676E95;font-style:italic;"># Must add EOS_TOKEN</span></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">formatting_prompts_func</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">examples</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    instructions </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> examples</span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">instruction</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#A6ACCD;">    inputs       </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> examples</span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">input</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#A6ACCD;">    outputs      </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> examples</span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">output</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#A6ACCD;">    texts </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[]</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">for</span><span style="color:#A6ACCD;"> instruction</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">input</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> output </span><span style="color:#89DDFF;font-style:italic;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">zip</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">instructions</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> inputs</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> outputs</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># Must add EOS_TOKEN, otherwise your generation will go on forever!</span></span>
<span class="line"><span style="color:#A6ACCD;">        text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> alpaca_prompt</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">format</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">instruction</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> input</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> output</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">+</span><span style="color:#A6ACCD;"> EOS_TOKEN</span></span>
<span class="line"><span style="color:#A6ACCD;">        texts</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">append</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">text</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">text</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> texts</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">pass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> datasets </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> load_dataset</span></span>
<span class="line"><span style="color:#A6ACCD;">dataset </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">load_dataset</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">shibing624/alpaca-zh</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">split</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">train</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">dataset </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> dataset</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">map</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">formatting_prompts_func</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">batched</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">True,)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> trl </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> SFTTrainer</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> transformers </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> TrainingArguments</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> unsloth </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> is_bfloat16_supported</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">trainer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">SFTTrainer</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">model</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> model</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">tokenizer</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">train_dataset</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> dataset</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">dataset_text_field</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">text</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">max_seq_length</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> max_seq_length</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">dataset_num_proc</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">2</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">packing</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">False,</span><span style="color:#82AAFF;"> </span><span style="color:#676E95;font-style:italic;"># Can make training 5x faster for short sequences.</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">args</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> TrainingArguments</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">per_device_train_batch_size</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">2</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">gradient_accumulation_steps</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">4</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">warmup_steps</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">5</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">max_steps</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">60</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">learning_rate</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">2e-4</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">fp16</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;font-style:italic;">not</span><span style="color:#82AAFF;"> is_bfloat16_supported</span><span style="color:#89DDFF;">(),</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">bf16</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> is_bfloat16_supported</span><span style="color:#89DDFF;">(),</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">logging_steps</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">optim</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">adamw_8bit</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">weight_decay</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">0.01</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">lr_scheduler_type</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">linear</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">seed</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">3407</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">output_dir</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">outputs</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">),</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">trainer_stats </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> trainer</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">train</span><span style="color:#89DDFF;">()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save_pretrained_gguf</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">dir</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">quantization_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">q4_k_m</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">push_to_hub_gguf</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">lumiseven/llama-3-8b-zh-q4_k_m</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> tokenizer</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">quantization_method</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">q4_k_m</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">token</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#F78C6C;">{token}</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre></div>`,29),t=[p];function e(c,r,F,D,y,A){return a(),n("div",null,t)}const u=s(o,[["render",e]]);export{C as __pageData,u as default};
