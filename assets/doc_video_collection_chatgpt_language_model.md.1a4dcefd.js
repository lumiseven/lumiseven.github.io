import{_ as t,c as o,o as n,b as e,d as a}from"./app.988cb848.js";const x=JSON.parse('{"title":"【人工智能】深入浅出ChatGPT大语言模型 | Andrej Karpathy | 三小时视频预习版 | 预训练 | 后训练 | 分词 | Transformer | 强化学习 | RLHF","description":"","frontmatter":{},"headers":[],"relativePath":"doc/video_collection/chatgpt_language_model.md","lastUpdated":1745843806000}'),r={name:"doc/video_collection/chatgpt_language_model.md"},s=e("h1",{id:"【人工智能】深入浅出chatgpt大语言模型-andrej-karpathy-三小时视频预习版-预训练-后训练-分词-transformer-强化学习-rlhf",tabindex:"-1"},[a("【人工智能】深入浅出ChatGPT大语言模型 | Andrej Karpathy | 三小时视频预习版 | 预训练 | 后训练 | 分词 | Transformer | 强化学习 | RLHF "),e("a",{class:"header-anchor",href:"#【人工智能】深入浅出chatgpt大语言模型-andrej-karpathy-三小时视频预习版-预训练-后训练-分词-transformer-强化学习-rlhf","aria-hidden":"true"},"#")],-1),c=e("div",{align:"center"},[e("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/56waReTN1_w",frameborder:"0",allowfullscreen:""})],-1),d=e("p",null,"近期，前OpenAI成员安德烈·卡帕西发布了一个长达三小时的视频，深入浅出地讲解了AI大模型从神经网络起源到DeepSeek-R1的进化历程。视频内容通俗易懂，即使非技术背景的观众也能轻松理解。",-1),l=e("p",null,"卡帕西首先从大语言模型的训练讲起，强调了预训练的重要性，将其比作模型“疯狂读书”的过程。预训练的第一步是收集和处理互联网上的公开信息，这些数据是大语言模型的“粮食”。 Common Crawl等项目自2007年起就开始抓取互联网信息，但互联网信息良莠不齐，需要进行过滤和处理，例如排除恶意网站，提取文本，并移除个人信息。",-1),_=e("p",null,"数据准备好后，需要进行Tokenization，也就是分词，将文本转化为模型可以识别的数字。卡帕西演示了GPT-4如何使用tiktokenizer工具将句子分解成token，每个token都有一个对应的ID。大语言模型可以处理有限长度的token序列，这个上限就是“上下文窗口长度”。模型通过预测下一个token，并与实际的token进行比较，不断调整内部参数，这个过程叫做反向传播。",-1),i=e("p",null,"Transformer是大语言模型的核心架构，它包含注意力机制、多头注意力、前馈神经网络、残差连接和层归一化等组件。卡帕西利用3D可视化工具，展示了token在Transformer神经网络中逐层被处理的过程。",-1),h=e("p",null,"训练完成后，模型就可以生成文本，这个过程叫做推理。模型根据预测的概率分布随机挑选token，生成文本的创造程度可以通过调整“温度系数”来控制。为了让模型成为真正的“助手”，还需要进行后训练，包括收集对话数据，教模型如何与人对话。对话数据需要遵循一些原则，例如“有用性”、“真实性”、“无害性”。",-1),p=e("p",null,"卡帕西还提到了大语言模型的“幻觉”问题，并介绍了通过提问和测试来了解模型知识水平的方法。模型可以使用搜索引擎等外部工具来获取更准确的信息。关于大语言模型是否有“自我意识”，卡帕西认为这并非一个内在属性，而是通过训练数据或系统提示塑造出来的。他强调了大语言模型的思考方式与人类不同，是离散的、一步一步的，模型的思考能力分散在每个token上。",-1),m=e("p",null,"卡帕西还提到了瑞士奶酪模型，认为大语言模型的智力参差不齐。为了解决这些问题，需要进行后训练，包括监督微调和强化学习。强化学习通过奖励和惩罚来训练模型，奖励函数的关键在于定义好的行为。DeepSeek R1就通过强化学习训练而成。对于写诗和写笑话等难以定义好坏的任务，可以采用基于人类反馈的强化学习（RLHF）。",-1),u=e("p",null,"最后，卡帕西展望了大语言模型的未来发展方向，包括多模态、Agent和融入生活。未来的模型不仅能处理文字，还能处理图片、声音、视频等。Agent可以自己完成复杂的任务。模型将像水和电一样，成为我们生活中不可或缺的一部分。",-1),f=[s,c,d,l,_,i,h,p,m,u];function k(g,T,w,A,R,b){return n(),o("div",null,f)}const y=t(r,[["render",k]]);export{x as __pageData,y as default};
