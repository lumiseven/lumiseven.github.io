import{_ as n,c as t,o as a,b as e,d as c}from"./app.4ceb1a7d.js";const H=JSON.parse('{"title":"【人工智能】HuggingFace发布LLM超大规模实战手册 | 200页报告解读 | 4000个Scaling实验 | 激活值重计算 | 梯度累积 | 数据并行 | 张量和序列并行 | 流水线并行","description":"","frontmatter":{},"headers":[],"relativePath":"doc/video_collection/huggingface_llm_manual.md","lastUpdated":1745843806000}'),o={name:"doc/video_collection/huggingface_llm_manual.md"},l=e("h1",{id:"【人工智能】huggingface发布llm超大规模实战手册-200页报告解读-4000个scaling实验-激活值重计算-梯度累积-数据并行-张量和序列并行-流水线并行",tabindex:"-1"},[c("【人工智能】HuggingFace发布LLM超大规模实战手册 | 200页报告解读 | 4000个Scaling实验 | 激活值重计算 | 梯度累积 | 数据并行 | 张量和序列并行 | 流水线并行 "),e("a",{class:"header-anchor",href:"#【人工智能】huggingface发布llm超大规模实战手册-200页报告解读-4000个scaling实验-激活值重计算-梯度累积-数据并行-张量和序列并行-流水线并行","aria-hidden":"true"},"#")],-1),i=e("div",{align:"center"},[e("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/MmQycrDLZ3U",frameborder:"0",allowfullscreen:""})],-1),s=e("p",null,"Hugging Face于2月19日发布了一本历时6个月完成的超大规模训练手册，旨在指导开发者如何在GPU集群上训练大型语言模型。这份手册基于超过4000次的scaling实验，涵盖了从基础理论到实际操作的各个方面，是深入了解大模型训练的宝贵资源。Hugging Face的CEO克莱门特·德朗格希望通过分享这些经验，推动AI领域的民主化，让更多组织和个人能够参与到AI模型的训练中，而不是将资源集中在少数大型企业手中。",-1),g=e("p",null,"大模型训练面临诸多挑战，其中最关键的是显存占用问题。模型权重、梯度、优化器状态和激活值等数据都需要存储在显存中，当模型参数达到70B时，仅权重和优化器状态就可能超过单张GPU的显存容量。此外，计算效率和通信开销也是不可忽视的挑战。我们需要尽可能提高GPU的利用率，减少数据传输和等待的时间，同时优化多GPU之间的通信，避免资源浪费和效率降低。",-1),_=e("p",null,"为了应对这些挑战，Hugging Face的手册中介绍了一系列技术手段。激活值重计算通过丢弃部分激活值来节省显存，并在反向传播时重新计算。梯度累积将批量数据拆分成多个微批次，分批计算梯度，避免一次性计算整个批量数据导致的显存爆炸。数据并行则是在多个GPU上并行处理不同的微批次数据，并通过all-reduce操作同步梯度。",-1),d=e("p",null,"为了进一步减少内存冗余，ZeRO（零冗余优化器）技术应运而生。ZeRO-1对优化器状态进行分区，ZeRO-2在ZeRO-1的基础上增加了对梯度的分区，而ZeRO-3（FSDP）则将分区扩展到了模型参数。尽管ZeRO能有效减少内存冗余，但无法处理激活值内存，此时张量并行技术就派上了用场。",-1),r=e("p",null,"张量并行通过按列或按行分区的方式，将张量分布到多个GPU上进行计算，从而减少矩阵乘法的激活内存。但张量并行在跨节点通信时速度较慢，当并行度超过8个GPU时，通信开销会变得非常明显。为了解决这些问题，序列并行技术减少了最大激活值的存储大小，上下文并行借鉴了序列并行中按序列长度拆分的思路，并引入了环形注意力技术，以高效处理GPU间的通信。",-1),u=e("p",null,"当模型权重无法在一个节点上存储时，就需要用到流水线并行技术。流水线并行将模型的各层分布到多个GPU上，每个GPU只需存储和处理部分模型层。为了解决流水线并行中GPU利用率不高的问题，出现了全前向全反向（AFAB）调度、一次前向一次反向（1F1B）调度和交错阶段技术等多种调度方法。此外，MoE（Mixture of Experts）模型还引入了专家并行技术，将每一层设置为多个并行模块，对token进行不同的处理。",-1),h=e("p",null,"Hugging Face在手册的制作过程中进行了大量的实验，在512个GPU上运行了超过4000次分布式实验，探索了不同的分布式训练架构和模型大小对训练效果的影响。通过这些实验，得到了丰富的数据，为我们在实际训练中选择合适的技术和配置提供了重要的参考依据。手册中还总结了将模型适配到内存中、满足目标全局批大小、优化训练吞吐量等关键步骤和策略。",-1),p=e("p",null,"总的来说，Hugging Face的超大规模训练手册为AI开发者、研究人员和企业提供了一套全面且实用的大语言模型训练指南。无论你是AI领域的新手还是资深专家，都能从这份手册中获取到有价值的信息，推动AI领域的民主化发展。",-1),m=[l,i,s,g,_,d,r,u,h,p];function f(P,U,G,F,O,x){return a(),t("div",null,m)}const Z=n(o,[["render",f]]);export{H as __pageData,Z as default};
